<!doctype html>
<html lang="en">
<head>
  <meta charset="utf-8" />
  <title>TRF — Transformer + XGBoost Stock Prediction</title>
  <meta name="viewport" content="width=device-width,initial-scale=1" />
  <meta name="description" content="Transformer + XGBoost pipeline for next-day stock movement with CrewAI decisioning and backtesting." />
  <link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;600;700&display=swap" rel="stylesheet">
  <style>
    :root{
      --bg0:#0b1220;
      --bg1:#0f172a;
      --ink:#e5e7eb;
      --ink-soft:#cbd5e1;
      --surface:#0b1020cc;
      --card:#0f172a;
      --card-alt:#0b1220;
      --border:#1f2937;
      --accent:#22d3ee;
      --accent-2:#a78bfa;
      --muted:#94a3b8;
      --chip:#111827;
      --chip-ink:#c7d2fe;
      --shadow: 0 10px 30px rgba(0,0,0,.35);
      --radius:16px;
      --radius-sm:12px;
    }
    *{box-sizing:border-box}
    html,body{height:100%}
    body{
      margin:0;
      font:16px/1.55 "Inter",system-ui,-apple-system,Segoe UI,Roboto,Ubuntu,"Helvetica Neue","Noto Sans",Arial;
      color:var(--ink);
      background:
        linear-gradient(rgba(255,255,255,0.03) 1px, transparent 1px),
        linear-gradient(90deg, rgba(255,255,255,0.03) 1px, transparent 1px),
        radial-gradient(60% 60% at 10% 10%, rgba(34,211,238,0.12), transparent 60%),
        radial-gradient(50% 50% at 90% 15%, rgba(167,139,250,0.12), transparent 65%),
        linear-gradient(180deg, var(--bg0) 0%, var(--bg1) 100%);
      background-size: 24px 24px, 24px 24px, auto, auto, auto;
      background-position: top left, top left, center, center, center;
      -webkit-font-smoothing:antialiased; -moz-osx-font-smoothing:grayscale;
    }
    a{color:var(--accent);text-decoration:none}
    a:hover{text-decoration:underline}

    .wrap{max-width:1120px;margin:0 auto;padding:28px 20px 60px}

    .top{
      position:sticky; top:0; z-index:10;
      display:flex; align-items:center; justify-content:space-between;
      padding:12px 16px; margin:10px auto 24px; max-width:1120px;
      background:var(--surface); backdrop-filter: blur(8px);
      border:1px solid var(--border); border-radius:var(--radius); box-shadow:var(--shadow);
    }
    .brand{display:flex;gap:12px;align-items:center}
    .logo{
      width:32px;height:32px;border-radius:8px;
      background: radial-gradient(100% 100% at 50% 0%, var(--accent) 0%, var(--accent-2) 100%);
      box-shadow: 0 6px 18px rgba(34,211,238,.35), inset 0 0 25px rgba(167,139,250,.25);
    }
    .brand h1{font-size:18px;margin:0}
    .nav a{margin-left:14px;padding:6px 10px;border-radius:8px;background:transparent;border:1px solid transparent}
    .nav a:hover{background:#0b122033;border-color:var(--border);text-decoration:none}
    .byline{font-size:14px;color:var(--ink-soft);margin-left:16px}

    header.hero{
      padding:28px; border-radius:var(--radius); border:1px solid var(--border);
      background:linear-gradient(180deg, #0b1226 0%, #0e162b 100%); box-shadow:var(--shadow);
    }
    .hero h2{font-size:clamp(22px,3vw,30px);margin:0 0 8px}
    .lead{margin:0 0 8px;color:var(--ink-soft)}
    .links a{margin-right:12px}

    .section{
      margin:24px 0; padding:22px; border:1px solid var(--border);
      background:linear-gradient(180deg, var(--card) 0%, var(--card-alt) 100%);
      border-radius:var(--radius); box-shadow:var(--shadow);
    }
    h3{margin:0 0 14px;font-size:clamp(18px,2.2vw,22px)}
    .grid{display:grid; gap:14px}
    .grid.cols-2{grid-template-columns:repeat(auto-fit,minmax(280px,1fr))}
    .grid.cols-1{grid-template-columns:1fr}

    ul{margin:0;padding-left:18px}
    li{margin:6px 0;color:var(--ink-soft)}

    .chips{display:flex;gap:8px;flex-wrap:wrap;margin-top:6px}
    .chip{padding:4px 10px;border-radius:999px;background:var(--chip);color:var(--chip-ink);font-size:12px;border:1px solid var(--border)}

    table{width:100%;border-collapse:collapse;font-size:14px}
    th,td{padding:10px;border-bottom:1px solid var(--border);vertical-align:top}
    th{text-align:left;color:var(--muted);font-weight:600}
    tbody tr:hover{background:#0b122e}

    code{
      background:#0b122e;border:1px solid var(--border);padding:2px 6px;border-radius:8px;
      font-family:ui-monospace,SFMono-Regular,Menlo,Monaco,Consolas,"Liberation Mono","Courier New",monospace
    }
    figure{margin:0}
    figcaption{color:var(--muted);font-size:13px;margin-top:6px}
    img{max-width:100%;height:auto;border-radius:14px;border:1px solid var(--border);display:block}

    details{border:1px dashed var(--border);border-radius:12px;padding:14px;background:#0b122e}
    summary{cursor:pointer;font-weight:600}

    .footer{margin-top:26px;color:var(--muted);font-size:13px;text-align:center}
    .mono{font-family:ui-monospace,SFMono-Regular,Menlo,Monaco,Consolas,"Liberation Mono","Courier New",monospace}
    .muted{color:var(--muted)}
  </style>
</head>
<body>
  <!-- Top bar -->
  <div class="top">
    <div class="brand">
      <div class="logo" aria-hidden="true"></div>
      <h1>TRF — Transformer + XGBoost</h1>
      <span class="byline">Author: <strong>Ameer Basha Shaik</strong></span>
    </div>
    <nav class="nav">
      <a href="#overview">Overview</a>
      <a href="#sprints">Sprints</a>
      <a href="#stories">User Stories</a>
      <a href="#artifacts">Artifacts</a>
      <a href="#commits">Commits</a>
      <a href="#run">How to Run</a>
      <a href="#appendix">Appendix</a>
    </nav>
  </div>

  <div class="wrap">

    <header class="hero" id="overview">
      <h2>Project & Contributions</h2>
      <!-- EXACT first paragraph as requested -->
      <p class="lead"><em>In the first paragraph I want to know what the project is and what you contributed. It must be factual. If it is exaggerated or what you were "supposed" to accomplish and I later find out it isn't true, you won't be hired and you might even be immediately fired.</em></p>
      <!-- Factual summary -->
      <p class="lead">
        This project implements a production-style pipeline that learns temporal features from OHLCV with a Transformer, feeds embeddings to XGBoost to predict next-day movement, requests a CrewAI BUY/SELL/HOLD decision, and validates via backtesting. I built: data ingestion & windowing, the Transformer model and embedding export, XGBoost training and inference JSON, CrewAI decision integration, backtesting with metrics, and basic integration tests (Sprints 2–4).
      </p>
      <div class="links">
        <a href="https://github.com/ameershaik6667/AI-Agent-Stock-Prediction/tree/ameer-sprint4" target="_blank">Code Repository</a>
        <a href="https://github.com/ameershaik6667/AI-Agent-Stock-Prediction/commits/ameer-sprint4/?author=ameershaik6667" target="_blank">Commits</a>
      </div>
      <div class="chips" aria-label="stack">
        <span class="chip">PyTorch</span><span class="chip">XGBoost</span><span class="chip">pandas</span>
        <span class="chip">yfinance</span><span class="chip">CrewAI</span><span class="chip">Backtesting</span>
      </div>
    </header>

    <section class="section">
      <h3>Architecture & Workflow</h3>
      <div class="grid cols-2">
        <ul>
          <li><strong>Data</strong>: Fetch OHLCV via <code>yfinance</code>, impute/normalize, create 20-day sliding windows.</li>
          <li><strong>Transformer</strong>: Self-attention encoder → 2-class logits (up/down); export logits as embeddings.</li>
          <li><strong>XGBoost</strong>: Train classifier on Transformer embeddings (grid-searched hyperparams) → <code>xgb_prob</code>.</li>
          <li><strong>Inference</strong>: JSON <code>{"date","transformer_score","xgb_prob"}</code>.</li>
        </ul>
        <ul>
          <li><strong>CrewAI</strong>: Map <code>xgb_prob</code> to BUY/SELL/HOLD (thresholds + prompt logic).</li>
          <li><strong>Backtesting</strong>: Daily signals → long/short sim with costs; compute Sharpe/return/drawdown.</li>
          <li><strong>Outputs</strong>: Decision record + backtest metrics; charts (equity curve, predicted vs actual).</li>
          <li><strong>Perf</strong>: Inference target ≤ 5s/window; secure API calls; no notebooks required.</li>
        </ul>
      </div>
    </section>

    <section class="section" id="sprints">
      <h3>Summary of Sprint Objectives</h3>
      <table>
        <thead>
          <tr><th>Sprint</th><th>Objective</th><th>Outcome</th></tr>
        </thead>
        <tbody>
          <tr>
            <td>2</td>
            <td>MVP data → Transformer → embeddings</td>
            <td>Implemented DataHandler, trained Transformer, exported/validated embeddings.</td>
          </tr>
          <tr>
            <td>3</td>
            <td>XGBoost training + end-to-end inference JSON</td>
            <td>Grid-searched XGBoost, saved model, emitted <code>transformer_score</code> & <code>xgb_prob</code>.</td>
          </tr>
          <tr>
            <td>4</td>
            <td>CrewAI decisions + backtesting + integration tests</td>
            <td>Integrated agents, built signals, simulated strategy, printed metrics, added tests.</td>
          </tr>
        </tbody>
      </table>
      <p class="muted" style="margin-top:8px">Task hour details are documented per sprint; full commit log linked above.</p>
    </section>

    <!-- NEW: User Stories & Task Summary -->
    <section class="section" id="stories">
      <h3>User Stories & Task Summary</h3>
      <ul>
        <li><strong>TRF.1 — Data Ingestion & Windowing:</strong> Fetched OHLCV via <code>yfinance</code>, imputed/normalized (z-score), built 20-day windows and temporal splits.</li>
        <li><strong>TRF.2 — Transformer Model:</strong> Implemented self-attention encoder (PyTorch), classification head, training loop with early stopping and checkpoint.</li>
        <li><strong>TRF.3 — Embedding Extraction:</strong> Froze Transformer; exported per-window logits/embeddings to CSV; validated shapes/labels.</li>
        <li><strong>TRF.4 — XGBoost Training:</strong> Loaded embeddings; grid-searched <code>n_estimators</code>, <code>max_depth</code>, <code>learning_rate</code>; saved best classifier.</li>
        <li><strong>TRF.5 — Inference Pipeline:</strong> Loaded models; produced <code>transformer_score</code> and <code>xgb_prob</code>; emitted compact JSON.</li>
        <li><strong>TRF.6 — CrewAI Decision Agent:</strong> Mapped <code>xgb_prob</code> to BUY/SELL/HOLD with strict JSON outputs.</li>
        <li><strong>TRF.7 — Backtesting:</strong> Generated daily signals; simulated long/short with costs; reported Sharpe, return, and drawdown.</li>
        <li><strong>TRF.8 — Visualization:</strong> Equity curve and predicted-vs-actual charts (see Artifacts).</li>
        <li><strong>TRF.9 — Integration & Performance:</strong> Basic integration tests; checked end-to-end latency target (≤ 5s/window).</li>
      </ul>
      <p class="muted" style="margin-top:8px">See Appendix for downloadable sprint task-hour documents and detailed narrative.</p>
    </section>

    <section class="section" id="artifacts">
      <h3>Key Artifacts</h3>
      <div class="grid cols-1">
        <figure>
          <img src="1.jpg" alt="CrewAI recommendation output (BUY/SELL/HOLD)">
          <figcaption>CrewAI decision JSON (inference). File: <code>1.jpg</code></figcaption>
        </figure>
        <figure>
          <img src="2.jpg" alt="Backtest results summary and equity curve">
          <figcaption>Backtest summary/metrics. File: <code>2.jpg</code></figcaption>
        </figure>
      </div>
    </section>

    <section class="section" id="commits">
      <h3>Commits (Authored)</h3>
      <table>
        <thead>
          <tr><th>Date</th><th>SHA</th><th>Description</th></tr>
        </thead>
        <tbody id="commits-body">
          <tr><td colspan="3" class="muted">Loading commits…</td></tr>
        </tbody>
      </table>
      <p class="muted" style="margin-top:8px">Source: GitHub API (branch <code>ameer-sprint4</code>, author <code>ameershaik6667</code>).</p>
    </section>

    <section class="section" id="run">
      <h3>How to Run (High-Level)</h3>
      <ol>
        <li>Create a Python env; install deps: <code>pandas</code>, <code>numpy</code>, <code>yfinance</code>, <code>torch</code>, <code>xgboost</code>, <code>scikit-learn</code>, <code>joblib</code>, <code>crewai</code>, <code>langchain_openai</code>.</li>
        <li>Train Transformer on 20-day windows; export logits as embeddings CSV; train/save XGBoost.</li>
        <li>Run inference: outputs <code>{"date","transformer_score","xgb_prob"}</code> and a CrewAI recommendation.</li>
        <li>Run backtesting to print Sharpe, total return, drawdown; see <code>1.jpg</code> and <code>2.jpg</code> for sample outputs.</li>
      </ol>
    </section>

    <section class="section" id="appendix">
      <h3>Appendix (Downloads)</h3>
      <p class="muted">Place these files in the same folder as this page in your GitHub repo so the links work on GitHub Pages.</p>
      <ul>
        <li><a href="Ameer Sprint 2 Task Hours.docx" download>Download — Ameer Sprint 2 Task Hours.docx</a></li>
        <li><a href="Ameer Sprint 3 Task Hours.docx" download>Download — Ameer Sprint 3 Task Hours.docx</a></li>
        <li><a href="Ameer Sprint 4 Task Hours.docx" download>Download — Ameer Sprint 4 Task Hours.docx</a></li>
      </ul>
      <details style="margin-top:10px">
        <summary>Scope & Acceptance (condensed)</summary>
        <p class="muted">
          Ingest OHLCV, train Transformer, extract embeddings for XGBoost, emit inference JSON, map to BUY/SELL/HOLD via CrewAI, and backtest with metrics/visualizations. Acceptance covers clean data windowing, model convergence, correct embedding export, improved accuracy from XGBoost vs baseline, ≤5s inference, correct decision mapping, and validated backtesting outputs.
        </p>
      </details>
    </section>

    <p class="footer">© 2025 • TRF — part of AI-Agent-Stock-Prediction</p>
  </div>

  <script>
    // Live commits table (keeps the page truthful & up to date)
    const COMMITS_API = "https://api.github.com/repos/ameershaik6667/AI-Agent-Stock-Prediction/commits?sha=ameer-sprint4&author=ameershaik6667&per_page=100";
    async function loadCommits(){
      const tbody = document.getElementById('commits-body');
      try{
        const res = await fetch(COMMITS_API);
        if(!res.ok) throw new Error('HTTP '+res.status);
        const commits = await res.json();
        if(!Array.isArray(commits) || !commits.length){
          tbody.innerHTML = '<tr><td colspan="3" class="muted">No commits found for this filter.</td></tr>';
          return;
        }
        tbody.innerHTML = commits.map(c=>{
          const sha = (c.sha||'').slice(0,7);
          const date = new Date(c.commit.author.date).toISOString().slice(0,10);
          const msg = (c.commit.message||'').split('\n')[0];
          const url = c.html_url;
          return `<tr>
              <td>${date}</td>
              <td class="mono"><a target="_blank" href="${url}">${sha}</a></td>
              <td>${escapeHtml(msg)}</td>
            </tr>`;
        }).join('');
      }catch(e){
        tbody.innerHTML = `<tr><td colspan="3" class="muted">Could not load commits (${e.message}). See the <a target="_blank" href="https://github.com/ameershaik6667/AI-Agent-Stock-Prediction/commits/ameer-sprint4/?author=ameershaik6667">commits page</a>.</td></tr>`;
      }
    }
    function escapeHtml(s){
      return s.replace(/[&<>"']/g, m => ({'&':'&amp;','<':'&lt;','>':'&gt;','"':'&quot;',"'":'&#39;'}[m]));
    }
    loadCommits();
  </script>
</body>
</html>
